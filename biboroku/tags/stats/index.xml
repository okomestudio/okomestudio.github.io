<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stats on Biboroku</title>
    <link>https://okomestudio.net/biboroku/tags/stats/</link>
    <description>Recent content in Stats on Biboroku</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 May 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://okomestudio.net/biboroku/tags/stats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Interpreting A/B Test using Python</title>
      <link>https://okomestudio.net/biboroku/2014/05/interpreting-ab-test-using-python/</link>
      <pubDate>Mon, 12 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://okomestudio.net/biboroku/2014/05/interpreting-ab-test-using-python/</guid>
      <description>Suppose we ran an A/B test with two different versions of a web page, \( a \) and \( b \), for which we count the number of visitors and whether they convert or not. We can summarize this in a contingency table showing the frequency distribution of the events:</description>
    </item>
    
    <item>
      <title>Brand Positioning by Correspondence Analysis</title>
      <link>https://okomestudio.net/biboroku/2014/05/brand-positioning-by-correspondence-analysis/</link>
      <pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://okomestudio.net/biboroku/2014/05/brand-positioning-by-correspondence-analysis/</guid>
      <description>I was reading an article about visualization techniques using multidimensional scaling (MDS), the correspondence analysis in particular. The example used R, but as usual I want to find ways to do it on Python, so here goes.
The correspondence analysis is useful when you have a two-way contingency table for which relative values of ratio-scaled data are of interest.</description>
    </item>
    
    <item>
      <title>PCA and Biplot using Python</title>
      <link>https://okomestudio.net/biboroku/2014/04/pca-and-biplot-using-python/</link>
      <pubDate>Thu, 24 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://okomestudio.net/biboroku/2014/04/pca-and-biplot-using-python/</guid>
      <description>There are several ways to run principal component analysis (PCA) using various packages (scikit-learn, statsmodels, etc.) or even just rolling out your own through singular-value decomposition and such. Visualizing the PCA result can be done through biplot. I was looking at an example of using prcomp and biplot in R, but it does not seem like there is a comparable plug-and-play way of generating a biplot on Python.</description>
    </item>
    
    <item>
      <title>Near-Duplicate Detection using MinHash: Background</title>
      <link>https://okomestudio.net/biboroku/2014/04/near-duplicate-detection-using-minhash-background/</link>
      <pubDate>Sat, 12 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://okomestudio.net/biboroku/2014/04/near-duplicate-detection-using-minhash-background/</guid>
      <description>There are numerous pieces of duplicate information served by multiple sources on the web. Many news stories that we receive from the media tend to originate from the same source, such as the Associated Press. When such contents are scraped off the web for archiving, a need may arise to categorize documents by their similarity (not in the sense of meaning of the text but the character-level or lexical matching).</description>
    </item>
    
  </channel>
</rss>